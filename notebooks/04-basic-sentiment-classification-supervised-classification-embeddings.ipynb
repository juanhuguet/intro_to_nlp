{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9451e58d-b889-4270-8f25-08d22d815275",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/juanhuguet/intro_to_nlp/blob/main/notebooks/04-basic-sentiment-classification-supervised-classification-embeddings.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0590681-1228-45df-8b48-c344bba06bf2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# The NLP revolution: embeddings\n",
    "\n",
    "The main takeaway of the exercise befor is we need to transform text into a mathematical representation, or vectors,\n",
    "to be able to feed the documents to machine learning algorithms so they can learn to map from the features to the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d39e745-14bf-462b-822e-32d2bdbad26c",
   "metadata": {},
   "source": [
    "Word embeddings are a type of vector representation for words in natural language processing (NLP) that have revolutionized the field by enabling more accurate and efficient text analysis.\n",
    "\n",
    "As we have seen before, early embedding techniques like CountVectorizer or TF-ID have limitations in capturing the complex relationships between words and their meanings. They are just a sparse word representation of the universe of words in the documents.\n",
    "\n",
    "To address this issue, more sophisticated techniques like Global Vectors for Word Representation (**GloVe**) and **Word2vec** were developed.\n",
    "\n",
    "These techniques use deep learning networks to transform sparse Bag of Word representation of text to dense vector representations by taking into account the context the word is appearing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cba85e-c49b-4a12-ad83-ea16a8325948",
   "metadata": {},
   "source": [
    "<img src=\"https://file.notion.so/f/f/003df94c-172d-46b4-9c84-4a2f90ef0ed1/2ac17577-2a5d-438c-89e3-3ed0a60a74e6/Untitled.png?id=922ae51c-a398-42c2-9b57-43ed4e0f99b9&table=block&spaceId=003df94c-172d-46b4-9c84-4a2f90ef0ed1&expirationTimestamp=1705622400000&signature=JZp11wX0MDrgzBd9lRbRAkDCj5nReB4-plB1R7Gkni4&downloadName=Untitled.png\" width=\"400\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e38e6c-4f1a-400f-8b34-b50431505181",
   "metadata": {},
   "source": [
    "# Import the basic libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f75ee97-043f-427f-bbfa-8794bd7c33c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920905ab-a635-40b9-906e-ce7796ae375d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5150d33-3d45-4c4b-b94e-f8eae733ae83",
   "metadata": {},
   "source": [
    "**We will use gensim to load the pre-trained vector embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e7b013-7873-4c1b-9dfa-9c4b723e8c93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c56676-2fe6-4196-bf1e-1d245677e78b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as gensim_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8023863e-4254-474e-a22c-b57df03852bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0ed1af-7706-40dc-8944-887e38367c04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb80ade2-5721-4e85-b1b3-88fc3708f1da",
   "metadata": {},
   "source": [
    "### Download the pre-trained word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ffb786-59ae-400a-bf58-e50d540b0ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2c15df-22fc-43ba-8ece-42336870bca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = '/root/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz'\n",
    "#model_path = '/Users/jhuguet/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3722fad-a41e-49d5-9038-f36ea00ab7aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_exists = Path(model_path).is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4656b49a-beae-46cf-8a8b-fc9951ebdf10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e7c8b7-d4bb-4e49-bf56-57af987c7eaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not file_exists:\n",
    "    model_name = 'word2vec-google-news-300'\n",
    "    model_path = gensim_api.load(model_name, return_path=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e0c371-4b35-4d3d-aec7-92da6a4fa490",
   "metadata": {},
   "source": [
    "#### Load the pre-trained word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3502d21-e3a2-46ef-a285-2deecd3d7f99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w2v_model = KeyedVectors.load_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a734a5c0-f26d-416f-8c17-81462154eaaa",
   "metadata": {},
   "source": [
    "This is a look-up table that have words as keys and embeddings as values.\n",
    "\n",
    ">Now, we can retrieve any embedding for the words in the available corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad35e489-dc27-4c43-af71-41562d10d4d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w2v_model[\"potato\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0445189-ef86-4c42-82c1-cf1ca8f9dc50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w2v_model[\"potato\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc039d59-72ca-4063-8ca5-d9ada627e5d2",
   "metadata": {},
   "source": [
    "Let's see if how we can operate with vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb8b783-7395-460d-b84a-44954de37385",
   "metadata": {},
   "source": [
    "<img src=\"https://file.notion.so/f/f/003df94c-172d-46b4-9c84-4a2f90ef0ed1/b5618b19-dbe1-435c-a7f2-0ae858a092f4/Untitled.png?id=f17dd007-e5aa-4ff4-a3a9-8200d4dd1d18&table=block&spaceId=003df94c-172d-46b4-9c84-4a2f90ef0ed1&expirationTimestamp=1705622400000&signature=MUqZi9enFd5_-yK0-DzoZRGp2ADJoFfutYAMpm4mPxw&downloadName=Untitled.png\" width=\"400\" height=\"200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2b2468-706c-4620-a4f9-44774ec532b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diff = w2v_model[\"king\"] - w2v_model[\"man\"] + w2v_model[\"woman\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5984fcd6-e55c-4157-aefe-2ca735daf13b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w2v_model.similar_by_vector(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b2e409-3f98-4ad6-8cc7-c1851b0d7739",
   "metadata": {},
   "source": [
    "## Let's use this embeddings as features for a classifier...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5b20d6-bb8d-4951-aa33-eb21ed99ad3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e999d2a-772d-48aa-a111-06423a75cfb3",
   "metadata": {},
   "source": [
    "#### Let's simulate some reviews..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e7a475-0d07-44cb-87d5-fbff87a73850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reviews_docs = [\"The food was good\",\n",
    "                \"The service was bad\",\n",
    "                \"The service and the food were good\",\n",
    "               ]\n",
    "\n",
    "labels = [\"positive\",\n",
    "          \"negative\",\n",
    "          \"positive\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d84c80-1f26-4e09-89b4-b84dfff3087e",
   "metadata": {},
   "source": [
    "### Let's use scikit learn to calculate the counts vectors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c419711-1df6-48a4-a0e5-6d328286cfba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sentence_embedding(sentence):\n",
    "    vecs = [w2v_model[x] for x in sentence.split(\" \") if x in w2v_model]\n",
    "    return np.mean(vecs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e110e34-0e0b-4c85-8083-399753aa303b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = [sentence_embedding(r) for r in reviews_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd3567d-fa7e-4d0a-9cbf-0d09b561a479",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reviews = pd.DataFrame(embeddings, index=reviews_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c05b6f6-d5af-4ed3-b697-132dab1f48cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reviews[\"sentiment\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa520e61-80a7-4374-9476-1ca7c39ec1cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e098f7cc-8e53-4021-b5d4-19900f345567",
   "metadata": {},
   "source": [
    "### Let's use these feature as an input for the classifier\n",
    "\n",
    "Note: the exercise here is only to demonstrate how we can learn from features extracted from text, of course, we need more examples and a proper modelling process that involves train/test split and validations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebda695-2b3c-486c-b55b-f8c15ba47541",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf_lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7ea09e-ac07-422f-bc0e-bc497ec9b418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = reviews.drop(columns=[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998d19b3-fd5c-43e3-85bf-e9dcf4355ab2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = reviews[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f1f4be-2bc2-43d2-beb5-b478b2b714f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf_lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97bcde4-4648-435e-8ab9-8b51ff0a4967",
   "metadata": {},
   "source": [
    "###Â Let' s make a prediction..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca19e36e-0a95-407b-95c7-4f51455e7ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_review = \"the weather was very good\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d29b3f-3415-4a81-9ec0-911e8d0450f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_review_vect = sentence_embedding(new_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b29af62-ce6a-48db-a9cb-75f80293c423",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf_lr.predict([new_review_vect])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93be6dfc-5541-4965-8323-7fa033211aec",
   "metadata": {},
   "source": [
    "## MAIN TAKEAWAY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e94b778-4798-4b44-9821-ca84667ab2dd",
   "metadata": {},
   "source": [
    "> Thanks to deep neural networks, word embeddings have evolved from sparse simple representations to dense representations that take into account the context the word normally appears. Also, these techniques show consistency in mathematical operations over the representations of the words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
