{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9451e58d-b889-4270-8f25-08d22d815275",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/juanhuguet/intro_to_nlp/blob/main/notebooks/04-basic-sentiment-classification-supervised-classification-embeddings.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0590681-1228-45df-8b48-c344bba06bf2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# The NLP revolution: embeddings\n",
    "\n",
    "The main takeaway of the exercise befor is we need to transform text into a mathematical representation, or vectors,\n",
    "to be able to feed the documents to machine learning algorithms so they can learn to map from the features to the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d39e745-14bf-462b-822e-32d2bdbad26c",
   "metadata": {},
   "source": [
    "Word embeddings are a type of vector representation for words in natural language processing (NLP) that have revolutionized the field by enabling more accurate and efficient text analysis.\n",
    "\n",
    "As we have seen before, early embedding techniques like CountVectorizer or TF-ID have limitations in capturing the complex relationships between words and their meanings. They are just a sparse word representation of the universe of words in the documents.\n",
    "\n",
    "To address this issue, more sophisticated techniques like Global Vectors for Word Representation (**GloVe**) and **Word2vec** were developed.\n",
    "\n",
    "These techniques use deep learning networks to transform sparse Bag of Word representation of text to dense vector representations by taking into account the context the word is appearing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cba85e-c49b-4a12-ad83-ea16a8325948",
   "metadata": {},
   "source": [
    "<img src=\"https://file.notion.so/f/f/003df94c-172d-46b4-9c84-4a2f90ef0ed1/2ac17577-2a5d-438c-89e3-3ed0a60a74e6/Untitled.png?id=922ae51c-a398-42c2-9b57-43ed4e0f99b9&table=block&spaceId=003df94c-172d-46b4-9c84-4a2f90ef0ed1&expirationTimestamp=1705622400000&signature=JZp11wX0MDrgzBd9lRbRAkDCj5nReB4-plB1R7Gkni4&downloadName=Untitled.png\" width=\"400\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e38e6c-4f1a-400f-8b34-b50431505181",
   "metadata": {},
   "source": [
    "# Import the basic libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f75ee97-043f-427f-bbfa-8794bd7c33c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "920905ab-a635-40b9-906e-ce7796ae375d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5150d33-3d45-4c4b-b94e-f8eae733ae83",
   "metadata": {},
   "source": [
    "**We will use gensim to load the pre-trained vector embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98e7b013-7873-4c1b-9dfa-9c4b723e8c93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2c56676-2fe6-4196-bf1e-1d245677e78b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as gensim_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8023863e-4254-474e-a22c-b57df03852bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce0ed1af-7706-40dc-8944-887e38367c04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb80ade2-5721-4e85-b1b3-88fc3708f1da",
   "metadata": {},
   "source": [
    "### Download the pre-trained word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86ffb786-59ae-400a-bf58-e50d540b0ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c2c15df-22fc-43ba-8ece-42336870bca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model_path = '/root/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz'\n",
    "model_path = '/Users/jhuguet/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3722fad-a41e-49d5-9038-f36ea00ab7aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_exists = Path(model_path).is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4656b49a-beae-46cf-8a8b-fc9951ebdf10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00e7c8b7-d4bb-4e49-bf56-57af987c7eaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not file_exists:\n",
    "    model_name = 'word2vec-google-news-300'\n",
    "    model_path = gensim_api.load(model_name, return_path=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e0c371-4b35-4d3d-aec7-92da6a4fa490",
   "metadata": {},
   "source": [
    "#### Load the pre-trained word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3502d21-e3a2-46ef-a285-2deecd3d7f99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w2v_model = KeyedVectors.load_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a734a5c0-f26d-416f-8c17-81462154eaaa",
   "metadata": {},
   "source": [
    "This is a look-up table that have words as keys and embeddings as values.\n",
    "\n",
    ">Now, we can retrieve any embedding for the words in the available corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad35e489-dc27-4c43-af71-41562d10d4d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model[\"potato\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0445189-ef86-4c42-82c1-cf1ca8f9dc50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.92968750e-01,  2.94921875e-01,  7.71484375e-02,  4.58984375e-01,\n",
       "        7.66601562e-02,  6.44531250e-02,  1.80664062e-01, -1.57226562e-01,\n",
       "       -5.46875000e-02, -3.75976562e-02,  2.16796875e-01, -8.85009766e-03,\n",
       "       -9.71679688e-02,  2.81982422e-02, -2.91015625e-01,  1.33789062e-01,\n",
       "       -1.25000000e-01,  1.67968750e-01, -2.15820312e-01, -1.36718750e-01,\n",
       "       -1.69921875e-01,  2.53906250e-01,  1.23535156e-01,  1.62109375e-01,\n",
       "        4.41894531e-02, -1.06445312e-01, -1.08886719e-01,  1.78710938e-01,\n",
       "        1.30859375e-01, -9.33837891e-03, -2.69531250e-01, -1.71875000e-01,\n",
       "        1.26953125e-01,  1.58203125e-01, -5.41992188e-02,  1.13281250e-01,\n",
       "        4.24804688e-02,  8.10546875e-02,  3.94531250e-01,  3.36914062e-02,\n",
       "        1.45874023e-02, -2.16796875e-01, -9.13085938e-02,  9.94873047e-03,\n",
       "       -4.46777344e-02, -3.30078125e-01,  4.07714844e-02,  9.37500000e-02,\n",
       "       -1.95312500e-02,  1.07421875e-01, -1.00585938e-01,  3.68652344e-02,\n",
       "        1.39648438e-01,  2.91748047e-02, -2.32421875e-01, -1.44531250e-01,\n",
       "       -2.24609375e-02, -9.71679688e-02, -5.14984131e-05, -2.39257812e-01,\n",
       "        1.78222656e-02,  4.02832031e-02, -1.15234375e-01, -3.07617188e-02,\n",
       "       -5.15136719e-02, -2.20703125e-01, -4.83398438e-02, -3.67187500e-01,\n",
       "        7.08007812e-02,  3.46679688e-02,  2.96875000e-01, -1.40625000e-01,\n",
       "       -4.98046875e-02, -9.86328125e-02, -2.94921875e-01, -4.34570312e-02,\n",
       "       -1.91406250e-01, -1.30859375e-01, -1.59179688e-01, -2.77343750e-01,\n",
       "        9.47265625e-02, -1.31835938e-01,  8.88671875e-02, -1.33789062e-01,\n",
       "        2.50000000e-01, -1.25000000e-01,  1.06811523e-02,  1.76757812e-01,\n",
       "       -1.45507812e-01, -1.37329102e-02, -2.92968750e-01, -1.00585938e-01,\n",
       "       -4.49218750e-02, -2.50000000e-01, -2.34985352e-03, -3.32031250e-01,\n",
       "       -1.42822266e-02,  1.80816650e-03,  1.71875000e-01, -1.74804688e-01,\n",
       "       -2.73437500e-01, -1.38671875e-01, -9.42382812e-02,  5.76171875e-02,\n",
       "        1.80664062e-02,  1.82342529e-03,  3.38745117e-03,  2.48046875e-01,\n",
       "       -2.59765625e-01, -3.20312500e-01, -2.57812500e-01, -2.08984375e-01,\n",
       "       -5.73730469e-02, -8.34960938e-02,  5.07812500e-02,  2.24609375e-01,\n",
       "        2.73437500e-01, -2.04101562e-01, -4.73632812e-02, -2.73437500e-01,\n",
       "       -7.22656250e-02, -1.16699219e-01, -2.36328125e-01, -1.66015625e-01,\n",
       "       -1.84570312e-01, -8.59375000e-02, -3.58886719e-02,  4.34570312e-02,\n",
       "        2.66113281e-02,  2.87109375e-01, -1.18164062e-01,  3.75976562e-02,\n",
       "       -2.08007812e-01, -1.89208984e-02,  1.34765625e-01,  3.45703125e-01,\n",
       "        1.33056641e-02, -4.73022461e-03,  5.32226562e-02, -5.17578125e-02,\n",
       "       -1.32812500e-01, -1.75781250e-01, -4.58984375e-02, -1.55273438e-01,\n",
       "        1.77001953e-02, -1.91406250e-01, -2.46582031e-02, -1.31835938e-01,\n",
       "       -3.28125000e-01,  1.75781250e-01,  2.35595703e-02, -1.70898438e-01,\n",
       "       -1.60156250e-01,  1.62353516e-02, -1.30004883e-02, -6.59179688e-02,\n",
       "       -3.24218750e-01, -5.49316406e-03, -1.23046875e-01, -2.06054688e-01,\n",
       "       -1.20117188e-01, -2.70996094e-02,  1.99218750e-01,  1.05957031e-01,\n",
       "        1.81640625e-01, -1.18652344e-01,  2.97851562e-02, -7.91015625e-02,\n",
       "        6.59179688e-02, -9.32617188e-02, -9.32617188e-02,  1.25976562e-01,\n",
       "       -6.22558594e-03, -1.43554688e-01, -3.39843750e-01, -2.10937500e-01,\n",
       "        1.62353516e-02,  4.05273438e-02, -4.39453125e-02,  2.87109375e-01,\n",
       "       -1.97753906e-02, -3.26171875e-01, -1.20605469e-01,  2.53906250e-01,\n",
       "        1.78710938e-01,  1.07910156e-01, -8.64257812e-02,  8.36181641e-03,\n",
       "       -5.85937500e-02,  1.61132812e-01, -8.05664062e-02,  1.52343750e-01,\n",
       "        2.25830078e-03, -2.22656250e-01,  2.91015625e-01,  1.40625000e-01,\n",
       "        5.15136719e-02,  6.78710938e-02, -7.91015625e-02, -5.18798828e-03,\n",
       "        1.74804688e-01, -1.20117188e-01,  1.03027344e-01, -1.23046875e-01,\n",
       "       -7.22656250e-02,  6.17675781e-02,  2.46093750e-01,  8.69140625e-02,\n",
       "       -3.34472656e-02, -1.26953125e-01, -9.96093750e-02,  4.49218750e-02,\n",
       "        9.81445312e-02, -7.32421875e-03, -4.48608398e-03, -2.28271484e-02,\n",
       "       -2.02636719e-02,  1.27563477e-02,  2.16796875e-01,  1.91406250e-01,\n",
       "        9.42382812e-02,  4.93164062e-02,  1.09375000e-01,  4.61425781e-02,\n",
       "       -8.83789062e-02, -9.66796875e-02,  1.68945312e-01, -1.18164062e-01,\n",
       "        2.11181641e-02,  5.49316406e-02,  2.03125000e-01, -5.41992188e-02,\n",
       "       -6.88476562e-02,  2.71484375e-01, -2.81250000e-01, -4.35546875e-01,\n",
       "        2.04101562e-01, -7.76367188e-02,  9.82666016e-03,  1.55029297e-02,\n",
       "        1.50390625e-01,  7.91015625e-02,  8.49609375e-02, -7.62939453e-03,\n",
       "        2.17285156e-02, -1.94335938e-01, -1.25976562e-01, -1.95312500e-02,\n",
       "        2.43164062e-01,  3.33984375e-01, -2.42187500e-01, -2.24609375e-01,\n",
       "        3.22265625e-01, -5.00488281e-02,  1.38671875e-01, -2.59765625e-01,\n",
       "        1.70898438e-01, -2.55859375e-01, -4.68750000e-02, -3.28125000e-01,\n",
       "        2.11914062e-01,  1.91406250e-01, -2.69531250e-01,  1.25976562e-01,\n",
       "        3.37890625e-01, -7.61718750e-02, -1.96289062e-01,  3.55468750e-01,\n",
       "       -1.96289062e-01, -2.23632812e-01, -1.02050781e-01,  8.10546875e-02,\n",
       "        2.05078125e-01, -5.19531250e-01, -1.64062500e-01, -1.48437500e-01,\n",
       "       -1.27563477e-02, -1.68945312e-01, -1.04003906e-01,  2.81250000e-01,\n",
       "        9.42382812e-02,  3.22265625e-01,  3.00781250e-01, -3.44848633e-03,\n",
       "       -1.43554688e-01, -3.75000000e-01, -2.01171875e-01,  1.79443359e-02,\n",
       "       -1.89453125e-01,  4.55078125e-01, -1.62109375e-01, -2.69531250e-01,\n",
       "       -2.18750000e-01, -9.21630859e-03,  2.96875000e-01,  1.46484375e-01,\n",
       "       -4.95605469e-02,  1.54296875e-01,  2.94921875e-01,  2.51953125e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model[\"potato\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc039d59-72ca-4063-8ca5-d9ada627e5d2",
   "metadata": {},
   "source": [
    "Let's see if how we can operate with vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb8b783-7395-460d-b84a-44954de37385",
   "metadata": {},
   "source": [
    "<img src=\"https://file.notion.so/f/f/003df94c-172d-46b4-9c84-4a2f90ef0ed1/b5618b19-dbe1-435c-a7f2-0ae858a092f4/Untitled.png?id=f17dd007-e5aa-4ff4-a3a9-8200d4dd1d18&table=block&spaceId=003df94c-172d-46b4-9c84-4a2f90ef0ed1&expirationTimestamp=1705622400000&signature=MUqZi9enFd5_-yK0-DzoZRGp2ADJoFfutYAMpm4mPxw&downloadName=Untitled.png\" width=\"400\" height=\"200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd2b2468-706c-4620-a4f9-44774ec532b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diff = w2v_model[\"king\"] - w2v_model[\"man\"] + w2v_model[\"woman\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5984fcd6-e55c-4157-aefe-2ca735daf13b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 0.8449392318725586),\n",
       " ('queen', 0.7300516366958618),\n",
       " ('monarch', 0.6454660296440125),\n",
       " ('princess', 0.6156251430511475),\n",
       " ('crown_prince', 0.5818676948547363),\n",
       " ('prince', 0.5777117609977722),\n",
       " ('kings', 0.5613663792610168),\n",
       " ('sultan', 0.5376776456832886),\n",
       " ('Queen_Consort', 0.5344247817993164),\n",
       " ('queens', 0.5289887189865112)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.similar_by_vector(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b2e409-3f98-4ad6-8cc7-c1851b0d7739",
   "metadata": {},
   "source": [
    "## Let's use this embeddings as features for a classifier...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d5b20d6-bb8d-4951-aa33-eb21ed99ad3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e999d2a-772d-48aa-a111-06423a75cfb3",
   "metadata": {},
   "source": [
    "#### Let's simulate some reviews..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93e7a475-0d07-44cb-87d5-fbff87a73850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reviews_docs = [\"The food was good\",\n",
    "                \"The service was bad\",\n",
    "                \"The service and the food were good\",\n",
    "               ]\n",
    "\n",
    "labels = [\"positive\",\n",
    "          \"negative\",\n",
    "          \"positive\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d84c80-1f26-4e09-89b4-b84dfff3087e",
   "metadata": {},
   "source": [
    "### Let's use scikit learn to calculate the counts vectors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c419711-1df6-48a4-a0e5-6d328286cfba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sentence_embedding(sentence):\n",
    "    vecs = [w2v_model[x] for x in sentence.split(\" \") if x in w2v_model]\n",
    "    return np.mean(vecs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e110e34-0e0b-4c85-8083-399753aa303b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = [sentence_embedding(r) for r in reviews_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6bd3567d-fa7e-4d0a-9cbf-0d09b561a479",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reviews = pd.DataFrame(embeddings, index=reviews_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c05b6f6-d5af-4ed3-b697-132dab1f48cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reviews[\"sentiment\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa520e61-80a7-4374-9476-1ca7c39ec1cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>The food was good</th>\n",
       "      <td>-0.071991</td>\n",
       "      <td>0.126236</td>\n",
       "      <td>0.027252</td>\n",
       "      <td>0.056519</td>\n",
       "      <td>-0.034729</td>\n",
       "      <td>0.034439</td>\n",
       "      <td>-0.003113</td>\n",
       "      <td>-0.056004</td>\n",
       "      <td>0.040527</td>\n",
       "      <td>0.075195</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010620</td>\n",
       "      <td>-0.116821</td>\n",
       "      <td>0.165497</td>\n",
       "      <td>0.005157</td>\n",
       "      <td>-0.001099</td>\n",
       "      <td>-0.028778</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.120356</td>\n",
       "      <td>-0.068047</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The service was bad</th>\n",
       "      <td>-0.003998</td>\n",
       "      <td>0.090164</td>\n",
       "      <td>0.126465</td>\n",
       "      <td>-0.019470</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>0.011475</td>\n",
       "      <td>0.038910</td>\n",
       "      <td>-0.001316</td>\n",
       "      <td>0.131226</td>\n",
       "      <td>0.143066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014526</td>\n",
       "      <td>-0.098389</td>\n",
       "      <td>0.125153</td>\n",
       "      <td>0.010895</td>\n",
       "      <td>0.049561</td>\n",
       "      <td>-0.077332</td>\n",
       "      <td>0.010620</td>\n",
       "      <td>0.095215</td>\n",
       "      <td>-0.081970</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The service and the food were good</th>\n",
       "      <td>-0.044434</td>\n",
       "      <td>0.090983</td>\n",
       "      <td>0.027608</td>\n",
       "      <td>0.056885</td>\n",
       "      <td>-0.032104</td>\n",
       "      <td>-0.014638</td>\n",
       "      <td>0.011332</td>\n",
       "      <td>-0.049624</td>\n",
       "      <td>0.036987</td>\n",
       "      <td>0.087952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039530</td>\n",
       "      <td>-0.084605</td>\n",
       "      <td>0.112651</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.040965</td>\n",
       "      <td>-0.048299</td>\n",
       "      <td>0.014771</td>\n",
       "      <td>0.080278</td>\n",
       "      <td>-0.078211</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           0         1         2         3   \n",
       "The food was good                  -0.071991  0.126236  0.027252  0.056519  \\\n",
       "The service was bad                -0.003998  0.090164  0.126465 -0.019470   \n",
       "The service and the food were good -0.044434  0.090983  0.027608  0.056885   \n",
       "\n",
       "                                           4         5         6         7   \n",
       "The food was good                  -0.034729  0.034439 -0.003113 -0.056004  \\\n",
       "The service was bad                 0.003479  0.011475  0.038910 -0.001316   \n",
       "The service and the food were good -0.032104 -0.014638  0.011332 -0.049624   \n",
       "\n",
       "                                           8         9  ...       291   \n",
       "The food was good                   0.040527  0.075195  ... -0.010620  \\\n",
       "The service was bad                 0.131226  0.143066  ...  0.014526   \n",
       "The service and the food were good  0.036987  0.087952  ... -0.039530   \n",
       "\n",
       "                                         292       293       294       295   \n",
       "The food was good                  -0.116821  0.165497  0.005157 -0.001099  \\\n",
       "The service was bad                -0.098389  0.125153  0.010895  0.049561   \n",
       "The service and the food were good -0.084605  0.112651  0.017578  0.040965   \n",
       "\n",
       "                                         296       297       298       299   \n",
       "The food was good                  -0.028778  0.001099  0.120356 -0.068047  \\\n",
       "The service was bad                -0.077332  0.010620  0.095215 -0.081970   \n",
       "The service and the food were good -0.048299  0.014771  0.080278 -0.078211   \n",
       "\n",
       "                                    sentiment  \n",
       "The food was good                    positive  \n",
       "The service was bad                  negative  \n",
       "The service and the food were good   positive  \n",
       "\n",
       "[3 rows x 301 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e098f7cc-8e53-4021-b5d4-19900f345567",
   "metadata": {},
   "source": [
    "### Let's use these feature as an input for the classifier\n",
    "\n",
    "Note: the exercise here is only to demonstrate how we can learn from features extracted from text, of course, we need more examples and a proper modelling process that involves train/test split and validations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ebda695-2b3c-486c-b55b-f8c15ba47541",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf_lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b7ea09e-ac07-422f-bc0e-bc497ec9b418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = reviews.drop(columns=[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "998d19b3-fd5c-43e3-85bf-e9dcf4355ab2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = reviews[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35f1f4be-2bc2-43d2-beb5-b478b2b714f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97bcde4-4648-435e-8ab9-8b51ff0a4967",
   "metadata": {},
   "source": [
    "### Let' s make a prediction..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca19e36e-0a95-407b-95c7-4f51455e7ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_review = \"the weather was very good\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12d29b3f-3415-4a81-9ec0-911e8d0450f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_review_vect = sentence_embedding(new_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b29af62-ce6a-48db-a9cb-75f80293c423",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr.predict([new_review_vect])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93be6dfc-5541-4965-8323-7fa033211aec",
   "metadata": {},
   "source": [
    "## MAIN TAKEAWAY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e94b778-4798-4b44-9821-ca84667ab2dd",
   "metadata": {},
   "source": [
    "> Thanks to deep neural networks, word embeddings have evolved from sparse simple representations to dense representations that take into account the context the word normally appears. Also, these techniques show consistency in mathematical operations over the representations of the words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
