{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad47cd1b-b1e0-44af-b48c-163a516b9ef9",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/juanhuguet/intro_to_nlp/blob/main/notebooks/07-gpt-openai-zero-shot-few-shot-learning.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca3ae3c-bbc5-4dba-8822-8bd68e0480ec",
   "metadata": {},
   "source": [
    "# Zero-Shot and Few-Shot Learning with OpenAI's GPT Models\n",
    "\n",
    "This Jupyter notebook provides an introduction to zero-shot and few-shot learning, and demonstrates how OpenAI's models can be used for data labeling and augmentation to train a smaller model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b198a8-0c75-4869-97d8-8fc83d477c9e",
   "metadata": {},
   "source": [
    "# Needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e20b7e4-ed3d-4042-a5e1-8e2b10031018",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "    \n",
    "try:\n",
    "    from openai import OpenAI\n",
    "except:\n",
    "    install(\"openai==1.8.0\")\n",
    "    from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec99609b-dbb0-44c4-9148-7bc5e1b92ab3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0163a3c-910a-4033-8e70-8a5bb9c26c71",
   "metadata": {},
   "source": [
    "## Set your key to communicate with openAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b8e0a10-bfbf-4787-b4ee-835f6f39d695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# It would be best to store it as a env var...\n",
    "api_key = 'your api key goes here'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da31c063-456c-4ad2-91a5-492a3aeeea30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a49616-6687-4496-bd88-40743bf97757",
   "metadata": {},
   "source": [
    "# Zero-shot learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b82d24c-3de0-4f84-a36c-6d2601067389",
   "metadata": {},
   "source": [
    "Zero-shot learning refers to the ability of a model to correctly perform a task without having seen any examples from that specific task during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00aeb0c9-1b63-4763-a4ba-a8da92b019f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_zero_shot = \"Translate the following English text to French: 'Hello, how are you?'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "590822a6-730b-4743-91e3-d81e245b90e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_response_from_openai(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ])\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55758b33-deba-467d-b506-f4384fb22186",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bonjour, comment Ã§a va ?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response_from_openai(prompt_zero_shot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b61c78-af3d-4f50-9782-875588e6f1d1",
   "metadata": {},
   "source": [
    "# Few-shot learning\n",
    "\n",
    "Few-shot learning involves providing the model with a small number of examples to guide its predictions for a specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb6a524c-cf63-41ab-82a1-e93e1807841a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"I love this product!\",\n",
    "    \"This is terrible.\",\n",
    "    \"The service was amazing.\",\n",
    "    \"Not satisfied with the quality.\"\n",
    "]\n",
    "\n",
    "scores = [\"positive\", \"negative\", \"positive\", \"negative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb766baf-1926-4662-8cc5-bc78e65c6264",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "examples_to_str = \"\"\n",
    "\n",
    "for sentence, score in list(zip(sentences, scores)):\n",
    "    examples_to_str += f\"Input: {sentence}\\nScore: {score}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0f4f78f-0acc-479e-86f8-16ed6dd5bb96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: I love this product!\n",
      "Score: positive\n",
      "Input: This is terrible.\n",
      "Score: negative\n",
      "Input: The service was amazing.\n",
      "Score: positive\n",
      "Input: Not satisfied with the quality.\n",
      "Score: negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(examples_to_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3323ab65-45f1-43d4-81c2-fd7866abf5a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hydrate_prompt_few_shot(new_sentence, examples_to_str=examples_to_str): \n",
    "    prompt_few_shot = \\\n",
    "    f\"\"\"Given a new sentence,classify its sentiment into positive or negative.\\nBelow are some examples:\\n\\n{examples_to_str}\\nInput: {new_sentence}\n",
    "    \"\"\"\n",
    "    return prompt_few_shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffc55906-5a7d-4652-bb6f-136c65e71401",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a new sentence,classify its sentiment into positive or negative.\n",
      "Below are some examples:\n",
      "\n",
      "Input: I love this product!\n",
      "Score: positive\n",
      "Input: This is terrible.\n",
      "Score: negative\n",
      "Input: The service was amazing.\n",
      "Score: positive\n",
      "Input: Not satisfied with the quality.\n",
      "Score: negative\n",
      "\n",
      "Input: even if it rains it is going to be a nice afternoon\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(hydrate_prompt_few_shot(\"even if it rains it is going to be a nice afternoon\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "990a3f86-1889-43ca-9b67-96fb963507f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Score: positive'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response_from_openai(hydrate_prompt_few_shot(\"even if it rains it is going to be a nice afternoon\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0a8a2d-ff9c-4392-875c-e3879f0a7641",
   "metadata": {},
   "source": [
    "# Data labeling example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "303cfc0e-25d2-4123-804c-cde1536f5eac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: A large green apple on a table. - Category: Fruit\n",
      "Sentence: A group of people standing on the beach. - Category: People\n",
      "Sentence: A new model of a smartphone is released. - Category: The sentence \"A new model of a smartphone is released\" would be classified under the category of Technology.\n"
     ]
    }
   ],
   "source": [
    "unlabeled_data = [\n",
    "  \"A large green apple on a table.\",\n",
    "  \"A group of people standing on the beach.\",\n",
    "  \"A new model of a smartphone is released.\"\n",
    "]\n",
    "\n",
    "labeled_data = []\n",
    "\n",
    "for text in unlabeled_data:\n",
    "    prompt_labeling = f\"Classify the following sentence into one of the categories: Fruit, People, Technology: '{text}'\"\n",
    "    category = get_response_from_openai(prompt_labeling)\n",
    "    labeled_data.append((text, category))\n",
    "\n",
    "for item in labeled_data:\n",
    "    print(f\"Sentence: {item[0]} - Category: {item[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73665b66-41fd-459b-b200-046bdb077ade",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Conclusion Highlights\n",
    "\n",
    "- **Versatile Toolset**: Generative LLMs serve as a multi-purpose toolkit, offering flexible solutions for a variety of data-related challenges.\n",
    "\n",
    "- **Zero-Shot Learning**: These models can perform tasks without prior specific examples, leveraging their extensive pre-trained knowledge.\n",
    "\n",
    "- **Few-Shot Learning**: With just a handful of examples, generative LLMs can quickly adapt to new tasks, dramatically reducing the need for large datasets.\n",
    "\n",
    "- **Data Labeling and Augmentation**: They can autonomously generate synthetic data and label existing data, mitigating the data scarcity bottleneck.\n",
    "\n",
    "- **Resource Efficiency**: Generative LLMs eliminate the need for extensive manual data annotation, saving time and resources.\n",
    "\n",
    "- **Rapid Prototyping**: The ability to quickly produce usable data accelerates the development and testing of new AI models and applications.\n",
    "\n",
    "Generative LLMs are revolutionizing the approach to AI development by providing a comprehensive set of capabilities that address data scarcity and labeling limitations, making AI more accessible and powerful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
